{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference(without finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "nb_params: 317837834\n",
      "Model loaded : /DATA/anand5/Audio_Work/models/LA_model.pth\n",
      "no. of eval trials 300\n",
      "/DATA/anand5/anaconda3/envs/Speech_A3/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "/DATA/anand5/anaconda3/envs/Speech_A3/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "/DATA/anand5/anaconda3/envs/Speech_A3/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "/DATA/anand5/anaconda3/envs/Speech_A3/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "/DATA/anand5/anaconda3/envs/Speech_A3/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "/DATA/anand5/anaconda3/envs/Speech_A3/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "Scores saved to custom_dataset_scores_2.txt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=2 python evaluate_custom.py --track=LA --is_eval --eval --model_path='/DATA/anand5/Audio_Work/models/LA_model.pth' --eval_output='custom_dataset_scores_2.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EER is: 0.4472222222222222\n",
      "The ROC-AUC is: 0.6098611111111112\n"
     ]
    }
   ],
   "source": [
    "!python compute_metrics.py custom_dataset_scores.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "nb_params: 317837834\n",
      "Model loaded : /DATA/anand5/BKUP/models/LA_model.pth\n",
      "no. of training trials 13956\n",
      "no. of validation trials 2826\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 0, 1], device='cuda:0')\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 0, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 0], device='cuda:0')\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 0, 1], device='cuda:0')\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 1], device='cuda:0')\n",
      "tensor([0, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 0], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 0, 0, 1], device='cuda:0')\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 1], device='cuda:0')\n",
      "tensor([0, 1, 1, 1], device='cuda:0')\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/DATA/anand5/BKUP/SU_A3/train_FOR.py\", line 298, in <module>\n",
      "    running_loss = train_epoch(train_loader,model, args.lr,optimizer, device)\n",
      "  File \"/DATA/anand5/BKUP/SU_A3/train_FOR.py\", line 100, in train_epoch\n",
      "    batch_loss.backward()\n",
      "  File \"/DATA/anand5/anaconda3/envs/Speech_A3/lib/python3.9/site-packages/torch/tensor.py\", line 245, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/DATA/anand5/anaconda3/envs/Speech_A3/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 145, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python train_FOR.py --model_path=\"/DATA/anand5/BKUP/models/LA_model.pth\" --track=LA --lr=0.000001 --batch_size=6 --loss=WCE  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Evaluation on FOR dataset after Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "nb_params: 317837834\n",
      "Model loaded : /DATA/anand5/BKUP/SU_A3/models/model_LA_WCE_100_6_1e-06/epoch_10.pth\n",
      "no. of eval trials 1088\n",
      "Scores saved to FOR_scores_LA_finetune.txt\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python evaluate_custom.py --track=LA --is_eval --eval --model_path='/DATA/anand5/BKUP/SU_A3/models/model_LA_WCE_100_6_1e-06/epoch_10.pth' --eval_output='FOR_scores_LA_finetune.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EER is: 0.0009191176470588235\n",
      "The ROC-AUC is: 0.9999898626730104\n"
     ]
    }
   ],
   "source": [
    "!python compute_metrics.py FOR_scores_LA_finetune.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Evaluation on Custom dataset after Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "nb_params: 317837834\n",
      "Model loaded : /DATA/anand5/BKUP/SU_A3/models/model_LA_WCE_100_6_1e-06/epoch_10.pth\n",
      "no. of eval trials 300\n",
      "Scores saved to custom_dataset_scores_LA_finetune.txt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python evaluate_custom.py --track=LA --is_eval --eval --model_path='/DATA/anand5/BKUP/SU_A3/models/model_LA_WCE_100_6_1e-06/epoch_10.pth' --eval_output='custom_dataset_scores_LA_finetune.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EER is: 0.11785714285714287\n",
      "The ROC-AUC is: 0.9514638447971782\n"
     ]
    }
   ],
   "source": [
    "!python compute_metrics.py custom_dataset_scores_LA_finetune.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=2 python evaluate_custom.py --track=LA --is_eval --eval --model_path='DATA/anand5/BKUP/models/Best_LA_model_for_DF.pth' --eval_output='custom_dataset_scores_DF.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EER is: 0.3930555555555556\n",
      "The ROC-AUC is: 0.6574537037037037\n"
     ]
    }
   ],
   "source": [
    "!python compute_metrics.py custom_dataset_scores_DF.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on FOR after finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "nb_params: 317837834\n",
      "Model loaded : /DATA/anand5/BKUP/SU_A3/models/model_LA_WCE_100_6_1e-06/epoch_11_DF.pth\n",
      "no. of eval trials 1088\n",
      "Scores saved to FOR_scores_DF_finetune.txt\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python evaluate_custom.py --track=LA --is_eval --eval --model_path='/DATA/anand5/BKUP/SU_A3/models/model_LA_WCE_100_6_1e-06/epoch_11_DF.pth' --eval_output='FOR_scores_DF_finetune.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EER is: 0.0\n",
      "The ROC-AUC is: 1.0\n"
     ]
    }
   ],
   "source": [
    "!python compute_metrics.py FOR_scores_DF_finetune.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on custom after finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "nb_params: 317837834\n",
      "Model loaded : /DATA/anand5/BKUP/SU_A3/models/model_LA_WCE_100_6_1e-06/epoch_11_DF.pth\n",
      "no. of eval trials 300\n",
      "Scores saved to custom_dataset_scores_DF_finetune.txt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python evaluate_custom.py --track=LA --is_eval --eval --model_path='/DATA/anand5/BKUP/SU_A3/models/model_LA_WCE_100_6_1e-06/epoch_11_DF.pth' --eval_output='custom_dataset_scores_DF_finetune.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EER is: 0.16666666666666663\n",
      "The ROC-AUC is: 0.9165277777777778\n"
     ]
    }
   ],
   "source": [
    "!python compute_metrics.py custom_dataset_scores_DF_finetune.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('Speech_A3': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62753774bfbc9fe616463cf61cfa51a65321bbda3ad434a732ff8752c47fd2be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
